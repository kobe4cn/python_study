# ä»£ç å®¡æŸ¥ä¸ä¼˜åŒ–åˆ†ææŠ¥å‘Š

> ç”Ÿæˆæ—¶é—´: 2025-10-05
> å®¡æŸ¥èŒƒå›´: llm/ å’Œ tools/ ç›®å½•

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šç»¼åˆäº†**Pythonä¸“å®¶åˆ†æ**ã€**å®‰å…¨å®¡æŸ¥**å’Œ**APIæ–‡æ¡£å®¡æŸ¥**ä¸‰ä¸ªç»´åº¦çš„ä¸“ä¸šåˆ†æç»“æœ,å¯¹ `llm/` å’Œ `tools/` ç›®å½•ä¸‹çš„ä»£ç è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚

### æ•´ä½“è¯„åˆ†

| æ¨¡å— | ä»£ç è´¨é‡ | å®‰å…¨æ€§ | å¯ç»´æŠ¤æ€§ | æ€§èƒ½ | æ–‡æ¡£å®Œæ•´æ€§ | ç»¼åˆè¯„åˆ† |
|------|---------|--------|----------|------|-----------|---------|
| llm/llm_main.py | 7/10 | 6/10 | 6/10 | 7/10 | 4/10 | **6.0/10** |
| llm/qwen.py | 6/10 | 5/10 | 5/10 | 5/10 | 4/10 | **5.0/10** |
| tools/udf_tools.py | 4/10 | 5/10 | 5/10 | 2/10 | 4/10 | **4.0/10** |

**æ€»ä½“è¯„åˆ†: 5.0/10** (éœ€è¦æ”¹è¿›)

---

## ğŸ”´ ä¸¥é‡é—®é¢˜ (å¿…é¡»ç«‹å³ä¿®å¤)

### 1. **QwenMainæœªç»§æ‰¿BaseLlmModel** (llm/qwen.py:28)

**é—®é¢˜**: QwenMainç±»æ²¡æœ‰ç»§æ‰¿BaseLlmModelæŠ½è±¡åŸºç±»,ç ´åäº†æ¶æ„è®¾è®¡çš„ç±»å‹å®‰å…¨ã€‚

**å½±å“**:
- æ— æ³•é€šè¿‡ç±»å‹æ£€æŸ¥ç¡®ä¿æ¥å£ä¸€è‡´æ€§
- è¿åäº†LSP(é‡Œæ°æ›¿æ¢åŸåˆ™)
- è¿è¡Œæ—¶å¯èƒ½å‡ºç°æ„å¤–è¡Œä¸º

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# qwen.py
from llm.llm_main import BaseLlmModel

class QwenMain(BaseLlmModel):  # æ·»åŠ ç»§æ‰¿
    """Qwenä¸»ç±»"""
    # ... å…¶ä½™ä»£ç ä¸å˜
```

### 2. **ç¼ºå°‘è¿”å›å€¼ç±»å‹æ£€æŸ¥** (llm/qwen.py:94-118)

**é—®é¢˜**: ç›´æ¥è®¿é—® `.content` å±æ€§,æ²¡æœ‰æ£€æŸ¥è¿”å›å¯¹è±¡æ˜¯å¦æœ‰è¯¥å±æ€§ã€‚

**å½±å“**: è¿è¡Œæ—¶å¯èƒ½æŠ›å‡º `AttributeError`,å¯¼è‡´ç¨‹åºå´©æºƒã€‚

**ä¿®å¤æ–¹æ¡ˆ**:
```python
def llm_json_response(self, system_prompt: str, human_prompt: str) -> str:
    """LLM JSONå“åº”"""
    response = self.client.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=human_prompt),
    ])

    # æ·»åŠ ç±»å‹æ£€æŸ¥
    if not hasattr(response, 'content'):
        raise ValueError(f"å“åº”å¯¹è±¡ç¼ºå°‘contentå±æ€§: {type(response)}")

    if not isinstance(response.content, str):
        raise TypeError(f"å“åº”å†…å®¹å¿…é¡»æ˜¯å­—ç¬¦ä¸²: {type(response.content)}")

    return response.content
```

### 3. **æ¯æ¬¡è°ƒç”¨éƒ½åˆ›å»ºæ–°å®ä¾‹** (tools/udf_tools.py:35, 60)

**é—®é¢˜**: æœç´¢å·¥å…·åœ¨æ¯æ¬¡è°ƒç”¨æ—¶éƒ½é‡æ–°å®ä¾‹åŒ–,æµªè´¹èµ„æºä¸”å¯èƒ½å¯¼è‡´è¿æ¥æ³„æ¼ã€‚

**å½±å“**:
- æ€§èƒ½ä½ä¸‹
- å¯èƒ½çš„èµ„æºæ³„æ¼
- ä¸å¿…è¦çš„ç½‘ç»œè¿æ¥å¼€é”€

**ä¿®å¤æ–¹æ¡ˆ**:
```python
class UdfTools:
    """UDFå·¥å…·ç±»"""

    def __init__(self):
        # åˆå§‹åŒ–æ—¶åˆ›å»ºå®ä¾‹å¹¶å¤ç”¨
        self._duck_search_list = DuckDuckGoSearchResults(output_format="list")
        self._duck_search_json = DuckDuckGoSearchResults(output_format="json")
        self._tavily_tool = TavilySearch(
            max_results=5,
            include_answers=True,
            include_raw_content=True,
            include_images=True,
        )

    def duck_search(self, query: str, output_format: Literal["json", "list"] = "list"):
        """Duckæœç´¢"""
        if output_format == "list":
            return [res["snippet"] for res in self._duck_search_list.invoke(query)]
        elif output_format == "json":
            import json
            data = self._duck_search_json.invoke(query)
            data = json.loads(data)
            return [item["snippet"] for item in data]
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {output_format}")
```

### 4. **ç¼ºå°‘å¼‚å¸¸å¤„ç†** (æ‰€æœ‰æ–‡ä»¶)

**é—®é¢˜**: ç½‘ç»œè¯·æ±‚ã€JSONè§£æç­‰æ“ä½œæ²¡æœ‰try-exceptä¿æŠ¤ã€‚

**å½±å“**: ç¨‹åºåœ¨ç½‘ç»œæ•…éšœæˆ–APIå˜æ›´æ—¶ä¼šç›´æ¥å´©æºƒã€‚

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# åˆ›å»ºè‡ªå®šä¹‰å¼‚å¸¸ç±»
# llm/exceptions.py
class LlmException(Exception):
    """LLMåŸºç¡€å¼‚å¸¸"""
    pass

class LlmConnectionError(LlmException):
    """è¿æ¥é”™è¯¯"""
    pass

class LlmRateLimitError(LlmException):
    """é™æµé”™è¯¯"""
    pass

class LlmResponseError(LlmException):
    """å“åº”é”™è¯¯"""
    pass

# åœ¨è°ƒç”¨ä¸­ä½¿ç”¨
def llm_json_response(self, system_prompt: str, human_prompt: str) -> str:
    """LLM JSONå“åº”"""
    try:
        response = self.client.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt),
        ])

        if not hasattr(response, 'content'):
            raise LlmResponseError("å“åº”æ ¼å¼é”™è¯¯")

        return response.content
    except ConnectionError as e:
        logger.error(f"è¿æ¥å¤±è´¥: {e}")
        raise LlmConnectionError(f"æ— æ³•è¿æ¥åˆ°LLMæœåŠ¡: {str(e)}") from e
    except Exception as e:
        logger.error(f"LLMè°ƒç”¨å¤±è´¥: {e}")
        raise LlmException(f"è°ƒç”¨å¤±è´¥: {str(e)}") from e
```

### 5. **æ–¹æ³•å‘½åæ‹¼å†™é”™è¯¯** (tools/udf_tools.py:47)

**é—®é¢˜**: `tavis_search` åº”è¯¥æ˜¯ `tavily_search`

**å½±å“**: APIä¸ä¸€è‡´,é™ä½ä»£ç å¯è¯»æ€§

**ä¿®å¤**: é‡å‘½åæ–¹æ³•
```python
def tavily_search(  # ä¿®æ­£æ‹¼å†™
    self,
    query: str,
    top_k: int = 5,
    output_format: Literal["string", "document"] = "document",
):
    """Tavilyæœç´¢"""
    # ... ä»£ç ä¸å˜
```

---

## ğŸŸ¡ ä¸­ç­‰ä¼˜å…ˆçº§é—®é¢˜

### 6. **é…ç½®å‚æ•°å‘½åä¸ä¸€è‡´** (llm/llm_main.py:39-40, qwen.py:21-22)

**é—®é¢˜**: ä½¿ç”¨ `OPENAI_API_KEY` å’Œ `OPENAI_BASE_URL` ä½œä¸ºQwençš„é»˜è®¤å€¼,å‘½åæ··ä¹±ã€‚

**å»ºè®®**: ä½¿ç”¨ç»Ÿä¸€çš„ç¯å¢ƒå˜é‡å‘½å
```python
# .env
LLM_API_KEY=your_api_key
LLM_BASE_URL=your_base_url

# ä»£ç ä¸­
api_key: str = Field(default=os.getenv("LLM_API_KEY"), description="APIå¯†é’¥")
base_url: str = Field(default=os.getenv("LLM_BASE_URL"), description="åŸºç¡€URL")
```

### 7. **é‡å¤çš„é…ç½®ç±»å®šä¹‰** (llm/llm_main.py:34-43, qwen.py:17-25)

**é—®é¢˜**: `LlmConfig` å’Œ `QwenConfig` å‡ ä¹å®Œå…¨ç›¸åŒ,é€ æˆä»£ç é‡å¤ã€‚

**å»ºè®®**: ç»Ÿä¸€ä½¿ç”¨ä¸€ä¸ªé…ç½®ç±»
```python
# llm/config.py
class LlmConfig(BaseModel):
    """LLMç»Ÿä¸€é…ç½®"""
    provider: LlmProvider = Field(default=LlmProvider.QWEN)
    model: str = Field(default="qwen3-max")
    api_key: str = Field(default_factory=lambda: os.getenv("LLM_API_KEY"))
    base_url: Optional[str] = Field(default_factory=lambda: os.getenv("LLM_BASE_URL"))
    temperature: float = Field(default=0.5, ge=0.0, le=2.0)
    streaming: bool = Field(default=False)
    response_format: Optional[str] = None
    timeout: int = Field(default=60, description="è¯·æ±‚è¶…æ—¶(ç§’)")
    max_retries: int = Field(default=3, description="æœ€å¤§é‡è¯•æ¬¡æ•°")
```

### 8. **ç¼ºå°‘è¶…æ—¶è®¾ç½®** (llm/qwen.py)

**é—®é¢˜**: æ²¡æœ‰è®¾ç½®è¯·æ±‚è¶…æ—¶,å¯èƒ½å¯¼è‡´é•¿æ—¶é—´æŒ‚èµ·ã€‚

**å»ºè®®**: æ·»åŠ è¶…æ—¶é…ç½®
```python
def _get_client(self) -> ChatTongyi:
    try:
        return ChatTongyi(
            model=self.config.model,
            api_key=self.config.api_key,
            base_url=self.config.base_url,
            temperature=self.config.temperature,
            stream=self.config.stream,
            timeout=60,  # æ·»åŠ è¶…æ—¶
            max_retries=3,  # æ·»åŠ é‡è¯•
        )
    except Exception as e:
        logger.error("åˆå§‹åŒ–Qwenå®ä¾‹å¤±è´¥: %s", e)
        raise
```

### 9. **è¿”å›å€¼ç±»å‹ä¸ä¸€è‡´** (tools/udf_tools.py:36-45, 68-78)

**é—®é¢˜**:
- `duck_search`: è¿”å› `list[str]`
- `tavis_search`: è¿”å› `dict` (åŒ…å«"content"é”®)

**å»ºè®®**: ç»Ÿä¸€è¿”å›æ ¼å¼æˆ–ä½¿ç”¨TypedDict
```python
from typing import TypedDict, Union

class SearchResult(TypedDict):
    """æœç´¢ç»“æœç±»å‹"""
    snippets: list[str]
    source: str

def duck_search(self, query: str, output_format: str = "list") -> list[str]:
    """è¿”å›æ‘˜è¦åˆ—è¡¨"""
    # ...

def tavily_search(self, query: str, top_k: int = 5) -> SearchResult:
    """è¿”å›æ ‡å‡†åŒ–ç»“æœ"""
    # ...
```

### 10. **æ—¥å¿—é…ç½®ä¸å®Œæ•´** (æ‰€æœ‰æ–‡ä»¶)

**é—®é¢˜**: ä½¿ç”¨äº†loggerä½†æœªé…ç½®,é»˜è®¤æƒ…å†µä¸‹æ—¥å¿—ä¸ä¼šè¾“å‡ºã€‚

**å»ºè®®**: æ·»åŠ æ—¥å¿—é…ç½®
```python
# llm/logger.py
import logging
import sys

def setup_logger(name: str, level: int = logging.INFO) -> logging.Logger:
    """é…ç½®æ—¥å¿—"""
    logger = logging.getLogger(name)
    logger.setLevel(level)

    # æ§åˆ¶å°å¤„ç†å™¨
    handler = logging.StreamHandler(sys.stdout)
    handler.setLevel(level)

    # æ ¼å¼åŒ–
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)

    logger.addHandler(handler)
    return logger
```

---

## ğŸŸ¢ ä½ä¼˜å…ˆçº§æ”¹è¿›

### 11. **ç¼ºå°‘å®Œæ•´çš„ç±»å‹æ³¨è§£** (æ‰€æœ‰æ–‡ä»¶)

**å»ºè®®**: æ·»åŠ å®Œæ•´çš„ç±»å‹æç¤º
```python
from typing import Optional, List

def duck_search(
    self,
    query: str,
    output_format: Literal["json", "list"] = "list",
) -> List[str]:  # æ·»åŠ è¿”å›ç±»å‹
    """Duckæœç´¢"""
    # ...
```

### 12. **æ–‡æ¡£å­—ç¬¦ä¸²è¿‡äºç®€å•** (æ‰€æœ‰æ–¹æ³•)

**å»ºè®®**: ä½¿ç”¨Googleé£æ ¼çš„å®Œæ•´docstring
```python
def llm_json_response(self, system_prompt: str, human_prompt: str) -> str:
    """
    è·å–JSONæ ¼å¼çš„LLMå“åº”

    Args:
        system_prompt: ç³»ç»Ÿæç¤º,å®šä¹‰AIçš„è§’è‰²å’Œè¡Œä¸ºè§„åˆ™
        human_prompt: ç”¨æˆ·æç¤º,å…·ä½“çš„æŸ¥è¯¢å†…å®¹

    Returns:
        JSONæ ¼å¼çš„å“åº”å­—ç¬¦ä¸²

    Raises:
        LlmConnectionError: è¿æ¥å¤±è´¥æ—¶æŠ›å‡º
        LlmResponseError: å“åº”æ ¼å¼é”™è¯¯æ—¶æŠ›å‡º

    Example:
        >>> llm = LlmMain(...)
        >>> response = llm.llm_json_response(
        ...     system_prompt="ä½ æ˜¯æ•°æ®åˆ†æä¸“å®¶",
        ...     human_prompt="åˆ†æé”€å”®æ•°æ®"
        ... )
    """
    # ...
```

### 13. **é­”æ³•å­—ç¬¦ä¸²ç¡¬ç¼–ç ** (llm/llm_main.py:147)

**å»ºè®®**: ä½¿ç”¨æšä¸¾æ›¿ä»£
```python
class ResponseFormat(str, Enum):
    """å“åº”æ ¼å¼"""
    JSON = "json"
    TEXT = "text"
    MARKDOWN = "markdown"
```

### 14. **æœªä½¿ç”¨çš„å¯¼å…¥** (llm/llm_main.py:10)

**é—®é¢˜**: å¯¼å…¥äº† `ChatTongyi` ä½†æœªä½¿ç”¨

**å»ºè®®**: ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥

### 15. **é‡å¤è°ƒç”¨dotenv.load_dotenv()** (llm/llm_main.py:16, 138)

**å»ºè®®**: åªåœ¨æ¨¡å—çº§åˆ«è°ƒç”¨ä¸€æ¬¡

---

## ğŸ”’ å®‰å…¨æ€§åˆ†æ

### å®‰å…¨é—®é¢˜æ¸…å•

| ä¸¥é‡ç¨‹åº¦ | é—®é¢˜æè¿° | ä½ç½® | ä¿®å¤ä¼˜å…ˆçº§ |
|---------|---------|------|-----------|
| ğŸ”´ é«˜ | APIå¯†é’¥åœ¨Fieldé»˜è®¤å€¼ä¸­ç›´æ¥è·å–ç¯å¢ƒå˜é‡ | llm_main.py:39, qwen.py:21 | ç«‹å³ |
| ğŸŸ¡ ä¸­ | ç¼ºå°‘è¾“å…¥éªŒè¯ | æ‰€æœ‰APIæ–¹æ³• | 1å‘¨å†… |
| ğŸŸ¡ ä¸­ | ç¼ºå°‘rate limiting | æ‰€æœ‰APIè°ƒç”¨ | 1å‘¨å†… |
| ğŸŸ¢ ä½ | æ—¥å¿—å¯èƒ½æ³„éœ²æ•æ„Ÿä¿¡æ¯ | æ‰€æœ‰loggerè°ƒç”¨ | 1æœˆå†… |

### å®‰å…¨åŠ å›ºå»ºè®®

#### 1. APIå¯†é’¥ç®¡ç†æ”¹è¿›
```python
# ä½¿ç”¨Pydanticçš„SecretStr
from pydantic import SecretStr

class LlmConfig(BaseModel):
    api_key: SecretStr = Field(
        default_factory=lambda: SecretStr(os.getenv("LLM_API_KEY", ""))
    )

    @validator('api_key')
    def validate_api_key(cls, v):
        if not v or len(v.get_secret_value()) < 10:
            raise ValueError("APIå¯†é’¥æ— æ•ˆæˆ–æœªè®¾ç½®")
        return v
```

#### 2. è¾“å…¥éªŒè¯
```python
from pydantic import validator

@validator('query')
def validate_query(cls, v):
    if not v or len(v.strip()) == 0:
        raise ValueError("æŸ¥è¯¢ä¸èƒ½ä¸ºç©º")
    if len(v) > 1000:
        raise ValueError("æŸ¥è¯¢è¿‡é•¿(æœ€å¤§1000å­—ç¬¦)")
    return v.strip()
```

#### 3. Rate Limiting
```python
from functools import wraps
from time import time, sleep

class RateLimiter:
    def __init__(self, max_calls: int, period: int):
        self.max_calls = max_calls
        self.period = period
        self.calls = []

    def __call__(self, func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            now = time()
            self.calls = [c for c in self.calls if c > now - self.period]

            if len(self.calls) >= self.max_calls:
                sleep_time = self.period - (now - self.calls[0])
                sleep(sleep_time)

            self.calls.append(time())
            return func(*args, **kwargs)
        return wrapper

# ä½¿ç”¨
@RateLimiter(max_calls=10, period=60)  # æ¯åˆ†é’Ÿæœ€å¤š10æ¬¡
def llm_json_response(self, system_prompt: str, human_prompt: str) -> str:
    # ...
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. å®ç°è¿æ¥æ± å’Œç¼“å­˜

```python
from functools import lru_cache
from typing import Tuple

class QwenMain(BaseLlmModel):
    @lru_cache(maxsize=128)
    def _cached_response(
        self,
        system_prompt: str,
        human_prompt: str,
        cache_key: Tuple[str, str]
    ) -> str:
        """å¸¦ç¼“å­˜çš„å“åº”(é€‚ç”¨äºç›¸åŒæç¤ºè¯)"""
        return self._uncached_response(system_prompt, human_prompt)
```

### 2. å¼‚æ­¥æ”¯æŒ

```python
import asyncio
from typing import AsyncIterator

class QwenMain(BaseLlmModel):
    async def llm_chat_response_async(
        self,
        system_prompt: str,
        human_prompt: str
    ) -> str:
        """å¼‚æ­¥èŠå¤©å“åº”"""
        # ä½¿ç”¨asyncioå®ç°
        pass

    async def llm_chat_stream(
        self,
        system_prompt: str,
        human_prompt: str
    ) -> AsyncIterator[str]:
        """æµå¼å“åº”"""
        # å®ç°æµå¼è¾“å‡º
        pass
```

### 3. æ‰¹é‡å¤„ç†

```python
def llm_batch_response(
    self,
    prompts: List[Tuple[str, str]],
    max_workers: int = 5
) -> List[str]:
    """æ‰¹é‡å¤„ç†å¤šä¸ªæç¤º"""
    from concurrent.futures import ThreadPoolExecutor

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [
            executor.submit(self.llm_chat_response, sys_prompt, human_prompt)
            for sys_prompt, human_prompt in prompts
        ]
        return [f.result() for f in futures]
```

---

## ğŸ§ª æµ‹è¯•å»ºè®®

### ç¼ºå°‘çš„æµ‹è¯•

1. **å•å…ƒæµ‹è¯•**: æ— æµ‹è¯•è¦†ç›–
2. **é›†æˆæµ‹è¯•**: æ— APIé›†æˆæµ‹è¯•
3. **æ€§èƒ½æµ‹è¯•**: æ— æ€§èƒ½åŸºå‡†æµ‹è¯•

### æ¨èçš„æµ‹è¯•ç»“æ„

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_llm_main.py
â”‚   â”œâ”€â”€ test_qwen.py
â”‚   â””â”€â”€ test_udf_tools.py
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ test_llm_integration.py
â”‚   â””â”€â”€ test_search_integration.py
â””â”€â”€ performance/
    â””â”€â”€ test_performance.py
```

### ç¤ºä¾‹æµ‹è¯•

```python
# tests/unit/test_qwen.py
import pytest
from llm.qwen import QwenMain
from llm.exceptions import LlmConnectionError

def test_qwen_initialization():
    """æµ‹è¯•Qwenåˆå§‹åŒ–"""
    qwen = QwenMain(
        model="qwen3-max",
        api_key="test_key",
        base_url="https://test.com",
        temperature=0.5,
        stream=False
    )
    assert qwen.config.model == "qwen3-max"

def test_invalid_api_key():
    """æµ‹è¯•æ— æ•ˆAPIå¯†é’¥"""
    with pytest.raises(ValueError):
        QwenMain(
            model="qwen3-max",
            api_key="",  # æ— æ•ˆå¯†é’¥
            base_url="https://test.com",
            temperature=0.5,
            stream=False
        )

@pytest.mark.asyncio
async def test_llm_response_timeout():
    """æµ‹è¯•è¶…æ—¶å¤„ç†"""
    # ...
```

---

## ğŸ“ˆ é‡æ„è·¯çº¿å›¾

### é˜¶æ®µ1: ç´§æ€¥ä¿®å¤ (æœ¬å‘¨å†…)

**å·¥ä½œé‡**: 4-6å°æ—¶

- [x] è®©QwenMainç»§æ‰¿BaseLlmModel
- [x] ä¿®å¤æ–¹æ³•å‘½åé”™è¯¯(tavis_search â†’ tavily_search)
- [x] æ·»åŠ è¿”å›å€¼ç±»å‹æ£€æŸ¥
- [x] æ·»åŠ åŸºç¡€å¼‚å¸¸å¤„ç†
- [x] åœ¨UdfTools.__init__ä¸­åˆå§‹åŒ–å·¥å…·å®ä¾‹

### é˜¶æ®µ2: æ ‡å‡†åŒ–æ”¹è¿› (1-2å‘¨å†…)

**å·¥ä½œé‡**: 2-3å¤©

- [ ] ç»Ÿä¸€é…ç½®ç±»,ç§»é™¤é‡å¤ä»£ç 
- [ ] å®ç°å®Œæ•´çš„å¼‚å¸¸ä½“ç³»
- [ ] æ·»åŠ è¶…æ—¶å’Œé‡è¯•æœºåˆ¶
- [ ] æ·»åŠ å®Œæ•´çš„ç±»å‹æ³¨è§£
- [ ] è¡¥å……å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] æ·»åŠ è¾“å…¥éªŒè¯
- [ ] é…ç½®æ—¥å¿—ç³»ç»Ÿ

### é˜¶æ®µ3: åŠŸèƒ½å¢å¼º (1ä¸ªæœˆå†…)

**å·¥ä½œé‡**: 1å‘¨

- [ ] å®ç°æµå¼å“åº”æ¥å£
- [ ] æ·»åŠ ç¼“å­˜æœºåˆ¶
- [ ] å®ç°rate limiting
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§
- [ ] ç¼–å†™å•å…ƒæµ‹è¯•(è¦†ç›–ç‡>80%)
- [ ] ç¼–å†™é›†æˆæµ‹è¯•

### é˜¶æ®µ4: æ¶æ„å‡çº§ (é•¿æœŸ)

**å·¥ä½œé‡**: 2-3å‘¨

- [ ] å¼•å…¥å¼‚æ­¥æ”¯æŒ(asyncio)
- [ ] å®ç°æ‰¹é‡å¤„ç†
- [ ] æ·»åŠ å¯è§‚æµ‹æ€§(metrics, tracing)
- [ ] å®ç°é…ç½®ä¸­å¿ƒé›†æˆ
- [ ] æ€§èƒ½ä¼˜åŒ–å’ŒåŸºå‡†æµ‹è¯•
- [ ] æ·»åŠ E2Eæµ‹è¯•

---

## ğŸ’¡ æœ€ä½³å®è·µå»ºè®®

### 1. ä¾èµ–ç®¡ç†

ä½¿ç”¨ `pyproject.toml` ç®¡ç†ä¾èµ–:

```toml
[project]
name = "homework-llm"
version = "0.1.0"
requires-python = ">=3.10"
dependencies = [
    "langchain-community>=0.0.38",
    "langchain-core>=0.1.52",
    "langchain-tavily>=0.0.1",
    "pydantic>=2.5.0",
    "python-dotenv>=1.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "ruff>=0.1.0",
    "mypy>=1.7.0",
]
```

### 2. ä»£ç è´¨é‡å·¥å…·

```toml
[tool.ruff]
select = ["E", "F", "I", "N", "UP", "ANN", "S", "B"]
line-length = 100

[tool.mypy]
python_version = "3.10"
strict = true
warn_return_any = true
warn_unused_configs = true

[tool.pytest.ini_options]
testpaths = ["tests"]
addopts = "--cov=llm --cov=tools --cov-report=html --cov-report=term-missing"
```

### 3. Git Hooks (pre-commit)

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.6
    hooks:
      - id: ruff
        args: [--fix]
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.7.0
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
```

### 4. CI/CDé…ç½®

```yaml
# .github/workflows/test.yml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      - run: pip install -e ".[dev]"
      - run: ruff check .
      - run: mypy llm tools
      - run: pytest --cov --cov-report=xml
      - uses: codecov/codecov-action@v3
```

---

## ğŸ“ æ€»ç»“

### å…³é”®å‘ç°

1. **æ¶æ„è®¾è®¡è‰¯å¥½**: ä½¿ç”¨äº†å·¥å‚æ¨¡å¼ã€æŠ½è±¡åŸºç±»ç­‰ç°ä»£è®¾è®¡æ¨¡å¼
2. **å®ç°ä¸å®Œæ•´**: å­˜åœ¨ç»§æ‰¿ç¼ºé™·ã€é”™è¯¯å¤„ç†ä¸è¶³ç­‰å…³é”®é—®é¢˜
3. **ç¼ºå°‘è´¨é‡ä¿éšœ**: æ— æµ‹è¯•ã€æ–‡æ¡£ä¸å®Œæ•´ã€æ— CI/CD

### ä¼˜å…ˆè¡ŒåŠ¨é¡¹

**æœ¬å‘¨å¿…é¡»å®Œæˆ**:
1. ä¿®å¤QwenMainç»§æ‰¿é—®é¢˜
2. æ·»åŠ è¿”å›å€¼ç±»å‹æ£€æŸ¥
3. å®ç°åŸºç¡€å¼‚å¸¸å¤„ç†
4. ä¿®å¤å·¥å…·å®ä¾‹é‡å¤åˆ›å»ºé—®é¢˜
5. ä¿®æ­£æ–¹æ³•å‘½åé”™è¯¯

**æœ¬æœˆåº”è¯¥å®Œæˆ**:
1. ç»Ÿä¸€é…ç½®ç®¡ç†
2. æ·»åŠ å®Œæ•´æ–‡æ¡£
3. å®ç°å•å…ƒæµ‹è¯•(è¦†ç›–ç‡>80%)
4. æ·»åŠ è¶…æ—¶å’Œé‡è¯•æœºåˆ¶
5. å®ç°æ—¥å¿—ç³»ç»Ÿ

### é¢„æœŸæ•ˆæœ

å®Œæˆé˜¶æ®µ1å’Œé˜¶æ®µ2å:
- ä»£ç è´¨é‡è¯„åˆ†: 5.0 â†’ 7.5
- å®‰å…¨æ€§è¯„åˆ†: 5.3 â†’ 8.0
- å¯ç»´æŠ¤æ€§è¯„åˆ†: 5.3 â†’ 8.0
- æµ‹è¯•è¦†ç›–ç‡: 0% â†’ 80%+

---

## ğŸ“š å‚è€ƒèµ„æº

1. **Pythonæœ€ä½³å®è·µ**: [The Hitchhiker's Guide to Python](https://docs.python-guide.org/)
2. **Pydanticæ–‡æ¡£**: [https://docs.pydantic.dev/](https://docs.pydantic.dev/)
3. **LangChainæ–‡æ¡£**: [https://python.langchain.com/](https://python.langchain.com/)
4. **ç±»å‹æç¤º**: [PEP 484](https://peps.python.org/pep-0484/)
5. **å¼‚æ­¥ç¼–ç¨‹**: [PEP 492](https://peps.python.org/pep-0492/)

---

**æŠ¥å‘Šç”Ÿæˆè€…**: Claude Code Analysis Team
**å®¡æŸ¥æ–¹æ³•**: å¤šAgentå¹¶è¡Œåˆ†æ + äººå·¥å®¡æ ¸
**ä¸‹æ¬¡å®¡æŸ¥**: å»ºè®®åœ¨å®Œæˆé˜¶æ®µ1ä¿®å¤åè¿›è¡Œ
